{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing for NYC Trees and Air Quality Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import os\n",
    "from typing import Tuple, Dict, Any\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data directories if they don't exist\n",
    "os.makedirs('./../data', exist_ok=True)\n",
    "for dir_name in ['raw_data', 'processed_data', 'log']:\n",
    "    basedir = './../data/'\n",
    "    os.makedirs(basedir+dir_name, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    \"\"\"Class to handle data processing for NYC Trees and Air Quality datasets\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.tree_data = None\n",
    "        self.air_quality_data = None\n",
    "        self.label_encoders = {}\n",
    "        \n",
    "    def load_data(self, tree_path: str, air_quality_path: str) -> None:\n",
    "        \"\"\"\n",
    "            Load raw data from CSV files\n",
    "            \n",
    "            Parameters:\n",
    "            -----------\n",
    "            tree_path: str\n",
    "                Path to tree census CSV file\n",
    "            air_quality_path: str\n",
    "                Path to air quality CSV file\n",
    "        \"\"\"\n",
    "        try:\n",
    "            logger.info(\"Loading tree census data...\")\n",
    "            self.tree_data = pd.read_csv(tree_path)\n",
    "            logger.info(f\"Loaded {len(self.tree_data)} tree records\")\n",
    "            \n",
    "            logger.info(\"Loading air quality data...\")\n",
    "            self.air_quality_data = pd.read_csv(air_quality_path)\n",
    "            logger.info(f\"Loaded {len(self.air_quality_data)} air quality records\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error loading data: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def clean_tree_data(self) -> None:\n",
    "        \"\"\"Clean and preprocess tree census data\"\"\"\n",
    "        try:\n",
    "            logger.info(\"Cleaning tree census data...\")\n",
    "            \n",
    "            # Remove duplicates\n",
    "            initial_len = len(self.tree_data)\n",
    "            self.tree_data.drop_duplicates(subset=['tree_id'], inplace=True)\n",
    "            logger.info(f\"Removed {initial_len - len(self.tree_data)} duplicate trees\")\n",
    "            \n",
    "            # Handle missing values\n",
    "            self.tree_data['tree_dbh'] = self.tree_data['tree_dbh'].fillna(\n",
    "                self.tree_data.groupby('spc_common')['tree_dbh'].transform('median')\n",
    "            )\n",
    "            \n",
    "            # Filter for living trees only\n",
    "            self.tree_data = self.tree_data[self.tree_data['status'] == 'Alive']\n",
    "            \n",
    "            # Convert coordinates to numeric\n",
    "            for col in ['latitude', 'longitude']:\n",
    "                self.tree_data[col] = pd.to_numeric(self.tree_data[col], errors='coerce')\n",
    "            \n",
    "            # Encode categorical variables\n",
    "            categorical_columns = ['health', 'spc_common', 'steward', 'guards', 'sidewalk']\n",
    "            for col in categorical_columns:\n",
    "                if col in self.tree_data.columns:\n",
    "                    self.label_encoders[col] = LabelEncoder()\n",
    "                    self.tree_data[f'{col}_encoded'] = self.label_encoders[col].fit_transform(\n",
    "                        self.tree_data[col].fillna('Unknown')\n",
    "                    )\n",
    "            \n",
    "            # Create health score (1-3)\n",
    "            health_mapping = {'Poor': 1, 'Fair': 2, 'Good': 3}\n",
    "            self.tree_data['health_score'] = self.tree_data['health'].map(health_mapping)\n",
    "            \n",
    "            logger.info(\"Tree data cleaning completed\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error cleaning tree data: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def clean_air_quality_data(self) -> None:\n",
    "        \"\"\"Clean and preprocess air quality data\"\"\"\n",
    "        try:\n",
    "            logger.info(\"Cleaning air quality data...\")\n",
    "            \n",
    "            # Remove duplicates\n",
    "            initial_len = len(self.air_quality_data)\n",
    "            self.air_quality_data.drop_duplicates(inplace=True)\n",
    "            logger.info(f\"Removed {initial_len - len(self.air_quality_data)} duplicate records\")\n",
    "            \n",
    "            # Convert dates\n",
    "            if 'start_date' in self.air_quality_data.columns:\n",
    "                self.air_quality_data['start_date'] = pd.to_datetime(\n",
    "                    self.air_quality_data['start_date']\n",
    "                )\n",
    "            \n",
    "            # Handle missing values in data_value\n",
    "            self.air_quality_data['data_value'] = pd.to_numeric(\n",
    "                self.air_quality_data['data_value'], \n",
    "                errors='coerce'\n",
    "            )\n",
    "            \n",
    "            # Create seasonal indicator\n",
    "            if 'start_date' in self.air_quality_data.columns:\n",
    "                self.air_quality_data['season'] = self.air_quality_data['start_date'].dt.quarter\n",
    "            \n",
    "            logger.info(\"Air quality data cleaning completed\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error cleaning air quality data: {str(e)}\")\n",
    "            raise\n",
    "    \n",
    "    def validate_data(self) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        Validate processed data and return validation results\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        Dict containing validation results\n",
    "        \"\"\"\n",
    "        validation_results = {\n",
    "            'trees': {\n",
    "                'total_records': len(self.tree_data),\n",
    "                'missing_values': self.tree_data.isnull().sum().to_dict(),\n",
    "                'value_ranges': {\n",
    "                    'tree_dbh': {\n",
    "                        'min': self.tree_data['tree_dbh'].min(),\n",
    "                        'max': self.tree_data['tree_dbh'].max()\n",
    "                    },\n",
    "                    'latitude': {\n",
    "                        'min': self.tree_data['latitude'].min(),\n",
    "                        'max': self.tree_data['latitude'].max()\n",
    "                    },\n",
    "                    'longitude': {\n",
    "                        'min': self.tree_data['longitude'].min(),\n",
    "                        'max': self.tree_data['longitude'].max()\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            'air_quality': {\n",
    "                'total_records': len(self.air_quality_data),\n",
    "                'missing_values': self.air_quality_data.isnull().sum().to_dict(),\n",
    "                'value_ranges': {\n",
    "                    'data_value': {\n",
    "                        'min': self.air_quality_data['data_value'].min(),\n",
    "                        'max': self.air_quality_data['data_value'].max()\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        logger.info(\"Data validation completed\")\n",
    "        return validation_results\n",
    "    \n",
    "    def save_processed_data(self, output_dir: str = 'processed_data') -> None:\n",
    "        \"\"\"\n",
    "        Save processed data and metadata to pickle files\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        output_dir: str\n",
    "            Directory to save processed data files\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Create timestamp for versioning\n",
    "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            \n",
    "            # Save processed datasets\n",
    "            with open(f'{output_dir}/tree_data_{timestamp}.pkl', 'wb') as f:\n",
    "                pickle.dump(self.tree_data, f)\n",
    "            \n",
    "            with open(f'{output_dir}/air_quality_data_{timestamp}.pkl', 'wb') as f:\n",
    "                pickle.dump(self.air_quality_data, f)\n",
    "            \n",
    "            # Save label encoders\n",
    "            with open(f'{output_dir}/label_encoders_{timestamp}.pkl', 'wb') as f:\n",
    "                pickle.dump(self.label_encoders, f)\n",
    "            \n",
    "            # Save validation results\n",
    "            validation_results = self.validate_data()\n",
    "            with open(f'{output_dir}/validation_results_{timestamp}.pkl', 'wb') as f:\n",
    "                pickle.dump(validation_results, f)\n",
    "            \n",
    "            logger.info(f\"All data saved to {output_dir} with timestamp {timestamp}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving processed data: {str(e)}\")\n",
    "            raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
